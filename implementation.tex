\section{Implementation}

\subsection{TensorFlow 101}
TensorFlow is an open-source software library for machine learning developed by the Google Brain Team.
The library models the computations in machine learning as data flow graphs.
Multidimensional data arrays are called tensors in TensorFlow.
Nodes in the graph represent mathematical operations between tensors,
such as add, multiply, softmax and dropout.
Graph edges represent the flow of tensors between nodes.
The computation graph based architecture allow researchers to run or train neural networks
on one or more CPUs or GPUs with unified API.

For general classification task, input $X$ and label $Y$ are defined as \textbf{placeholder}s
and feed into the computation graph at running time using a dictionary.
The graph of a typical deep learning model have three parts.
The \textbf{inference} graph should be built so that output predictions could be returned as tensor.
For example, in the multilayer perceptron case, inference graph contains all iterative
computation~\ref{Equ:MLPFeedForward1}-\ref{Equ:MLPFeedForward2} in the feed-forwarding steps.
The \textbf{loss} graph should compute the loss function defined by particular models.
Usually it is either cross-entropy or mean-squared error averaged across the batch data.
The loss graph will be optimized, usually minimized, by the \textbf{train} part.
This optimization can be conducted by various optimizing algorithms, such as gradient descent,
Momentum, RMSProp.
After sufficient steps of batch training, we can evaluate the trained model with inference
graph and compare the predictions with the test dataset labels.
TensorFlow also provides various useful utilities for training models and running experiments.
Using a Saver, we are able to checkpoint the training process used to later restore a model for
further training or evaluation.
User can also use Summary nodes to log the snapshot of interest variables, which can be
automatically visualized by TensorBoard.

\subsection{NetLearner}
We provide a library NetLearner that wraps up several deep learning models on the basis
of TensorFlow.
NetLearner modularizes multilayer perceptron, restricted Boltzmann machine, sparse autoencoder
and masking-noise autoencoder.

